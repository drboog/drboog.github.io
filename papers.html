<!DOCTYPE html>
<html>
    <head>
    <style>
        body{
            padding-top: 5%;
            padding-left: 28%;
            padding-right: 28%;
            padding-bottom: 5%;
        }
    </style>
    </head>

    <body>
            <div class="section-heading"><h2>Publications</h2></div>
                <ul>

                    <li>
                        <div class="paper">
                            <div class="abs_photo"><img src="./index_files/hu.jpg" width="100" height="100" align="right"></div>
                            <div class="title"><text id="small-caps"> <a href="https://arxiv.org/abs/2211.15388">Shifted Diffusion for Text-to-image Generation</a></text> <iframe src="https://ghbtns.com/github-btn.html?user=drboog&repo=Shifted_Diffusion&type=star&count=true&size=small" frameborder="0" scrolling="0" width="150" height="20" title="GitHub"></iframe> </div>
                            <div class="authors"> <b>Yufan Zhou</b>, Bingchen Liu, Yizhe Zhu, Xiao Yang, Changyou Chen, Jinhui Xu. </div>
                            <div class="venue"> <i> IEEE Conference on Computer Vision and Pattern Recognition </i> (<b>CVPR</b>), 2023.</div>
                            <div class="abs"> <font color="#00539CFF">We propose a method termed Corgi, which can better generate image embeddings from text inside multimodal embedding space.<br> It benefits both standard and language-free text-to-image generation. And yes, I do have a Corgi.</font> </i></div>
                        </div>
                    </li>
                    <br>

                    <li>
                        <div class="paper">
                            <div class="title"><text id="small-caps"> <a href="https://arxiv.org/abs/2111.13792">LAFITE: Towards Language-Free Training for Text-to-Image Generation</a></text> <iframe src="https://ghbtns.com/github-btn.html?user=drboog&repo=Lafite&type=star&count=true&size=small" frameborder="0" scrolling="0" width="150" height="20" title="GitHub"></iframe> </div>
                            <div class="authors"> <b>Yufan Zhou</b>, Ruiyi Zhang, Changyou Chen, Chunyuan Li, Chris Tensmeyer, Tong Yu, Jiuxiang Gu, Jinhui Xu, Tong Sun. </div>
                            <div class="venue"> <i> IEEE Conference on Computer Vision and Pattern Recognition </i> (<b>CVPR</b>), 2022.</div>
                            <div class="abs"><font color="#00539CFF">Our proposed work, Lafite, is the first work which can successfully train text-to-image generation model with image-only dataset.</font></i></div>
                        </div>
                    </li>
                    <br>

                    <li>
                        <div class="paper">
                            <div class="title"><text id="small-caps"> <a href="https://ojs.aaai.org/index.php/AAAI/article/view/20270">TiGAN: Text-Based Interactive Image Generation and Manipulation</a></text></div>
                            <div class="authors"> <b> Yufan Zhou</b>, Ruiyi Zhang, Jiuxiang Gu, Chris Tensmeyer, Tong Yu, Changyou Chen, Jinhui Xu, Tong Sun.</div>
                            <div class="venue"> <i>  AAAI conference on Artificial Intelligence </i> (<b>AAAI</b>), 2022.</div>
                        </div>
                    </li>
                    <br>


                    <li>
                        <div class="paper">
                            <div class="title"><text id="small-caps"> <a href = "https://arxiv.org/pdf/2102.03909.pdf"  target="_blank"> Meta-Learning with Neural Tangent Kernels</a></text></div>
                            <div class="authors"> <b>Yufan Zhou*</b>, Zhenyi Wang*, Jiayi Xian, Changyou Chen, Jinhui Xu.</div>
                            <div class="venue"> <i> International Conference on Learning Representations</i> (<b>ICLR</b>), 2021.</div>
                        </div>
                    </li>
                    <br>


                    <li>
                        <div class="paper">
                            <div class="title"><text id="small-caps"> <a href = "https://arxiv.org/pdf/2011.00593.pdf"  target="_blank"> MixKD: Towards Efficient Distillation of Large-scale Language Models</a></text></div>
                            <div class="authors"> Kevin J Liang, Weituo Hao, Dinghan Shen, <b>Yufan Zhou</b>, Weizhu Chen, Changyou Chen, Lawrence Carin.</div>
                            <div class="venue"> <i> International Conference on Learning Representations</i> (<b>ICLR</b>), 2021.</div>
                        </div>
                    </li>
                    <br>


                    <li>
                        <div class="paper">
                            <div class="title"><text id="small-caps"> <a href = "https://arxiv.org/pdf/2010.01761.pdf"  target="_blank">Learning Manifold Implicitly via Explicit Heat Kernel Learning</a></text></div>
                            <div class="authors"> <b>Yufan Zhou</b>, Changyou Chen, Jinhui Xu.</div>
                            <div class="venue"> <i> Conference on Neural Information Processing Systems</i> (<b>NeurIPS</b>), 2020.</div>
                        </div>
                    </li>
                    <br>

                    <li>
                        <div class="paper">
                            <div class="title"><text id="small-caps"> <a href="https://ieeexplore.ieee.org/document/9098640"  target="_blank">Weakly-supervised Brain Tumor Classification with Global Diagnosis Label</a> <font color="#FF0000">(Oral)</font></text> </div>
                            <div class="authors"> <b>Yufan Zhou</b>, Zheshuo Li, Chunwei Ma, Mingchen Gao, Changyou Chen, Hong Zhu, Jinhui Xu.</div>
                            <div class="venue"> <i> IEEE International Symposium on Biomedical Imaging </i> (<b>ISBI</b>), 2020.</div>
                        </div>
                    </li>
                    <br>

                    <li>
                        <div class="paper">
                            <div class="title"><text id="small-caps"> <a href="https://ojs.aaai.org//index.php/AAAI/article/view/6135"  target="_blank">Variational Adversarial Kernel Learned Imitation Learning</a> <font color="#FF0000">(Spotlight)</font></text></div>
                            <div class="authors"> Fan Yang, Alina Vereshchaka, <b>Yufan Zhou</b>, Changyou Chen, Wen Dong.</div>
                            <div class="venue"> <i> AAAI conference on Artificial Intelligence </i> (<b>AAAI</b>), 2020.</div>
                        </div>
                    </li>
                    <br>
                    
                    <li>
                        <div class="paper">
                            <div class="title"><text id="small-caps"> <a href="https://arxiv.org/pdf/1912.10150.pdf"  target="_blank">Learning Diverse Stochastic Action-Generators by Learning Smooth Latent Transitions</a> <font color="#FF0000">(Spotlight)</font></text> </div>
                            <div class="authors">Zhenyi Wang, Ping Yu, Yang Zhao, Ruiyi Zhang, <b>Yufan Zhou</b>, Junsong Yuan, Changyou Chen.</div>
                            <div class="venue"> <i> AAAI conference on Artificial Intelligence </i>  (<b>AAAI</b>), 2020.</div>
                        </div>
                    </li>
                    <br>

                     <li>
                        <div class="paper">
                            <div class="title"><text id="small-caps">Towards Aligned Layout Generation via Diffusion Model with Aesthetic Constraints</text> </div>
                            <div class="authors"> Jian Chen, Ruiyi Zhang, <b>Yufan Zhou</b>, Rajiv Jain, Zhiqiang Xu, Ryan Rossi, Changyou Chen. </div>
                            <div class="venue"> <i>Workshop on Diffusion Models</i> at <b>NeurIPS</b> 2023. </div>
                        </div>
                    </li>
                    <br>

                    <li>
                        <div class="paper">
                            <div class="title"><text id="small-caps">Enhanced Visual Instruction Tuning for Text-Rich Image Understanding</text> </div>
                            <div class="authors"> Yanzhe Zhang, Ruiyi Zhang, Jiuxiang Gu, <b>Yufan Zhou</b>, Nedim Lipka, Diyi Yang, Tong Sun. </div>
                            <div class="venue"> <i>Workshop on Instruction Tuning and Instruction Following</i> at <b>NeurIPS</b> 2023. </div>
                        </div>
                    </li>
                    <br>

                    <li>
                        <div class="paper">
                            <div class="title"><text id="small-caps"> <a href="https://cse.buffalo.edu/~mgao8/files/2018_BrainLes.pdf">Holistic Brain Tumor Screening and Classification Based on DenseNet and Recurrent Neural Network</a> </text></div>
                            <div class="authors"> <b>Yufan Zhou</b>, Zheshuo Li, Hong Zhu, Changyou Chen, Mingchen Gao, Kai Xu, Jinhui Xu.</div>
                            <div class="venue"> <i> International Conference on Medical Image Computing and Computer Assisted Intervention, Brain Lesion Workshop </i> (<b>BrainLes</b>, <b>MICCAI</b>), 2018.</div>
                        </div>
                    </li>


                </ul>

            <hr>
            <div class="section-heading"><h2>Manuscripts/Preprints</h2></div>
                <ul>
                    <li>
                        <div class="paper">
                            <div class="title"><text id="small-caps"> <a href="https://arxiv.org/abs/2312.03045">Customization Assistant for Text-to-Image Generation</a></text></div>
                            <div class="authors"> <b>Yufan Zhou</b>, Ruiyi Zhang, Jiuxiang Gu, Tong Sun. </div>
                            <div class="abs"><font color="#00539CFF"> An assistant which can generate creative images for specific user-input subject along with text explanation and elaboration in 2-5 seconds, without any fine-tuning.</font></i></div>
                        </div>
                    </li>
                    <br>

                    <li>
                        <div class="paper">
                            <div class="title"><text id="small-caps"> <a href="https://llavar.github.io/">LLaVAR: Enhanced Visual Instruction Tuning for Text-rich Image Understanding</a></text> <iframe src="https://ghbtns.com/github-btn.html?user=SALT-NLP&repo=LLaVAR&type=star&count=true&size=small" frameborder="0" scrolling="0" width="150" height="20" title="GitHub"></iframe>  </div>
                            <div class="authors"> Yanzhe Zhang, Ruiyi Zhang, Jiuxiang Gu, <b>Yufan Zhou</b>, Nedim Lipka, Diyi Yang, Tong Sun. </div>
                        </div>
                    </li>
                    <br>


                    <li>
                        <div class="paper">
                            <div class="title"><text id="small-caps"> <a href="https://arxiv.org/abs/2305.13579">Enhancing Detail Preservation for Customized Text-to-Image Generation: A Regularization-Free Approach</a></text> <iframe src="https://ghbtns.com/github-btn.html?user=drboog&repo=ProFusion&type=star&count=true&size=small" frameborder="0" scrolling="0" width="150" height="20" title="GitHub"></iframe>  </div>
                            <div class="authors"> <b>Yufan Zhou</b>, Ruiyi Zhang, Tong Sun, Jinhui Xu. </div>
                            <div class="abs"><font color="#00539CFF">A novel framework for customized text-to-image generation without the use of regularization. <br> We can efficiently customize a large-scale text-to-image generation model on single GPU, with only one image provided by the user.</font></i></div>

                        </div>
                    </li>
                    <br>

                    <li>
                        <div class="paper">
                            <div class="title"><text id="small-caps"> <a href="https://arxiv.org/abs/2210.14124"> Lafite2: Few-shot Text-to-Image Generation</a></text></div>
                            <div class="authors"> <b>Yufan Zhou</b>, Chunyuan Li, Changyou Chen, Jinhui Xu. </div>
                        </div>
                    </li>
                    <br>
                    <li>
                        <div class="paper">
                            <div class="title"><text id="small-caps"> <a href="https://arxiv.org/abs/2112.03502">A Generic Approach for Enhancing GANs by Regularized Latent Optimization</a></text></div>
                            <div class="authors"> <b>Yufan Zhou</b>, Chunyuan Li, Changyou Chen, Jinhui Xu. </div>
                        </div>
                    </li>
                    <br>

                    <li>
                        <div class="paper">
                            <div class="title"><text id="small-caps"> <a href="https://arxiv.org/abs/2105.04538">Learning High-Dimensional Distributions with Latent Neural Fokker-Planck Kernels</a></text></div>
                            <div class="authors"> <b>Yufan Zhou</b>, Changyou Chen, Jinhui Xu.</div>
                        </div>
                    </li>
                    <br>

                    <li>
                        <div class="paper">
                            <div class="title"><text id="small-caps"> <a href="https://arxiv.org/abs/1912.00979">KernelNet: A Data-Dependent Kernel Parameterization for Deep Generative Modeling</a></text></div>
                            <div class="authors"> <b>Yufan Zhou</b>, Changyou Chen, Jinhui Xu.</div>
                        </div>
                    </li>
                    <br>

                    <li>
                        <div class="paper">
                            <div class="title"><text id="small-caps"> <a href="https://arxiv.org/abs/2005.07869">Graph Neural Networks with Composite Kernels</a></text></div>
                            <div class="authors"> <b>Yufan Zhou</b>, Jiayi Xian, Changyou Chen, Jinhui Xu.</div>
                        </div>
                    </li>
                </ul>

    </body>
</html>